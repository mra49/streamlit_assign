{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mra49/streamlit_assign/blob/main/capstonePostUnifyingipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtCX-kCzd_oZ"
      },
      "source": [
        "###3-4)product_type cleaning for remington brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XajrfqEu309J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJAbVJtdxE2B",
        "outputId": "6b15c8fd-ca32-49df-f22e-81f55c20c7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-caa7c61e0865>:1: DtypeWarning: Columns (5,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/data/checkpoint_before_spaCy_eval.csv\")\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/data/checkpoint_before_spaCy_eval.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3eQMQXiZ3_Cu"
      },
      "outputs": [],
      "source": [
        "df_rem = pd.read_csv(\"/content/drive/MyDrive/data/df_brand_remington dictionary.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL8R6gT2Ubgw",
        "outputId": "43694c80-32c6-484a-8dfe-a0fdf5b19029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Item Number', 'Item Description', 'Brand', 'remington_codes',\n",
              "       'product_type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_rem.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nS0wj9rB6jVS"
      },
      "outputs": [],
      "source": [
        "# Filter df_rem for rows where the brand is 'Remington'\n",
        "remington_df_rem = df_rem[df_rem['Brand'].str.lower() == 'remington']\n",
        "\n",
        "# Create a dictionary mapping Item Number to product_type for Remington items\n",
        "remington_product_type_dict = pd.Series(remington_df_rem['product_type'].values,\n",
        "                                        index=remington_df_rem['Item Number']).to_dict()\n",
        "item_dict = remington_product_type_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBFLKpZrGV4L",
        "outputId": "a58b9188-9065-4950-e10d-9cfdd53ed876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'1604509': 'Hair Straightner', '3326558': 'women shaver ', '1602944': 'Hair Straightner', '1602739': 'Hair Dryer', '334302': 'men shaver ', '1602746': 'Hair Dryer', '165015': 'Stylist', '168015': 'Hair Curler', '356772': 'Women Shaver', '168012': 'Hair Straightner', '1604503': 'Hair Curler', '3326527': 'Men Shaver', '168014': 'Hair Curler', '1602722': 'Hair Dryer', '1602753': 'Hair Dryer', '3514123': 'Women Shaver', '3304471': 'Men Shaver', '1604502': 'Hair Curler', '356771': 'Nail kit', '334286': 'Men Shaver ', '1623819': 'stylist', '1637700': 'Hair Straightner', '168009': 'Hair Dryer', '3346104': 'Women Shaver', '120035': 'hair brush ', '3342907': 'Men Shaver', '1604501': 'Hair Curler', '1623826': 'Hair Curler', '168001': 'Hair Dryer', '3300122': 'Men Shaver', '334022': 'Men Shaver', '33184': 'Men Shaver', '3300124': 'Men Shaver', '3300125': 'Men Shaver', '3300126': 'Men Shaver', '168959': 'Hair Straightner', '1602723': 'Hair Straightner', '1690668': 'Hair Straightner', '1647271': 'Hair Straightner', '16185': 'Hair Straightner', '1602724': 'Hair Straighner', '1602968': 'hair straightner ', '3326510': 'men shaver ', '3524322': 'women shaver ', '3564325': 'women shaver ', '352310': 'women shaver ', '3326571': 'men shaver ', '334289': 'men shaver ', '352311': 'facial care ', '3346105': 'women shaver ', '1604507': 'brush ', '3564332': 'women shaver ', '165012': 'hair dryer ', '168013': 'hair straightner ', '1637687': 'hair curler ', '1600382': 'hair curler ', '1600383': 'hair straightner ', '1600385': 'hair straightner ', '1600386': 'hair straightner ', '1685125': 'hair curler ', '1600381': 'men shaver ', '165007': 'hair dryer ', '3564356': 'women shaver ', '1600392': 'hair dryer ', '3304495': 'men shaver ', '1685127': 'hair straightner ', '1603576': 'hair curler '}\n"
          ]
        }
      ],
      "source": [
        "print(remington_product_type_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U05DK6xmV817"
      },
      "outputs": [],
      "source": [
        "item_dict = {str(key): value for key, value in item_dict.items()}\n",
        "\n",
        "# Load or define your DataFrame 'df'\n",
        "# df = pd.read_csv('your_file.csv') or continue with your existing DataFrame\n",
        "\n",
        "# Ensure the 'Item Number' column is of string type\n",
        "df['Item Number'] = df['Item Number'].astype(str)\n",
        "\n",
        "# Optional: Strip any leading/trailing spaces\n",
        "df['Item Number'] = df['Item Number'].str.strip()\n",
        "\n",
        "# Create a mask for rows where Item Number is in the dictionary\n",
        "mask = df['Item Number'].isin(item_dict.keys())\n",
        "\n",
        "# Apply the mapping only to rows where the mask is True\n",
        "df.loc[mask, 'product_type'] = df.loc[mask, 'Item Number'].map(item_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b9U8OKE_WqQ",
        "outputId": "c9718fb7-a864-4169-f68f-d7ac68d22157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Item Number      product_type\n",
            "0     1604509  Hair Straightner\n",
            "1       56240              mask\n",
            "2       56938        shower gel\n",
            "3       56960        shower gel\n",
            "4       57332               NaN\n"
          ]
        }
      ],
      "source": [
        "# Assuming df is your original DataFrame and it's already loaded\n",
        "\n",
        "# Filter df for rows where the brand is 'Remington' and select only 'Item Number' and 'product_type'\n",
        "df_check = df[['Item Number', 'product_type']]\n",
        "\n",
        "# Display the first few rows of df_check\n",
        "print(df_check.head())\n",
        "df_check.to_csv(\"check_remsPT.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kQFTFKI8dKPs"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"df\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66RYIgYjzLc"
      },
      "source": [
        "###3-5)Clean Brand product_type Category and Subcategory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-0LQQu8Lmdgs"
      },
      "outputs": [],
      "source": [
        "# Rename the column\n",
        "df.rename(columns={'Unified Description': 'Unified IN'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4-XcYJDeouO"
      },
      "source": [
        "####3-5.1)quick Brand Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Isdjy7EegT1l"
      },
      "outputs": [],
      "source": [
        "df['Brand'] = df['Brand'].replace('cleannet', 'clean net')\n",
        "\n",
        "to_replace_brand = {\n",
        "    \"Keplex\": [\"semi prmnnt\", \"shampoo\",\"keplex\"],\n",
        "    \"babyliss\" : [\"electrical\"],\n",
        "    \"reflet argin\": [\"reflet arg\"],\n",
        "    \"vitality\": [\"tubes\"],\n",
        "    \"k.keratin\": [\"conditioner\",\"keratine\", \"coloration\"]\n",
        "\n",
        "}\n",
        "# Replace values in 'Brand',\n",
        "for new_value, old_values in to_replace_brand.items():\n",
        "    df['Brand'].replace(old_values, new_value, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LjC3b7XX5lWU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and is already loaded\n",
        "\n",
        "# Function to update the Brand based on Item Description\n",
        "def update_brand(row):\n",
        "    if row['Item Description'].lower().startswith('wahl'):\n",
        "        return 'wahl'\n",
        "    return row['Brand']\n",
        "\n",
        "# Apply the function to each row\n",
        "df['Brand'] = df.apply(update_brand, axis=1)\n",
        "\n",
        "# Now df will have the 'Brand' updated to 'wahl' where the Item Description starts with 'wahl'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8mwnULq3elru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31494b04-0d57-4549-b9cd-4999ac9abed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "style           42013\n",
            "foamy           38922\n",
            "clean net       12448\n",
            "hawai            8768\n",
            "remington         517\n",
            "Keplex            151\n",
            "wahl              110\n",
            "k.keratin         109\n",
            "vitality           90\n",
            "reflet argin       84\n",
            "treatment          70\n",
            "babyliss           60\n",
            "justformen         35\n",
            "marvelisse         16\n",
            "gl/cr/serum        14\n",
            "elect stra         14\n",
            "straightnr         11\n",
            "cover spray        11\n",
            "make-up            11\n",
            "shaver mchn        10\n",
            "oxydant             9\n",
            "onemon col          9\n",
            "men section         9\n",
            "serum               8\n",
            "mim                 6\n",
            "wellness            6\n",
            "curling mac         6\n",
            "caviarine           5\n",
            "h.accessor          5\n",
            "wax                 4\n",
            "scissors            4\n",
            "promo item          4\n",
            "h.r.machine         4\n",
            "hairdrs bag         3\n",
            "face care           3\n",
            "promotion           3\n",
            "mask/oil            3\n",
            "fresheners          3\n",
            "promo               2\n",
            "wax machine         2\n",
            "combs               2\n",
            "rmvl paste          2\n",
            "h.extension         2\n",
            "glowy               2\n",
            "gent                1\n",
            "krys-krtn           1\n",
            "r.m.(b)             1\n",
            "shaving imp         1\n",
            "loufa               1\n",
            "zero                1\n",
            "mantenance          1\n",
            "h.clipper           1\n",
            "idm/fixedas         1\n",
            "Name: Brand, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count the occurrences of each unique value in the 'Brand' column\n",
        "brand_counts = df['Brand'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(brand_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qXgHmyop11lh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9raeY9CMVNU"
      },
      "source": [
        "####3.5-2)product_type cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "X9LUigwCMb9z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your DataFrame 'df'\n",
        "\n",
        "# List of specific product types to replace with 'shampoo'\n",
        "to_replace = [\n",
        "    \"shampoo\", \"sh.\", \"sh\", \"shampo\", \"shampoo1.125l*2\",\n",
        "    \"shanpoo\", \"shamp\", \"sham\", \"sh.gallon\", \"sh/gel\",\n",
        "    \"shamp.meridian\", \"sha.\"\n",
        "]\n",
        "\n",
        "# Replace each instance in 'product_type' with 'shampoo'\n",
        "df['product_type'] = df['product_type'].replace(to_replace, 'shampoo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Y5n5EHWaY2C5"
      },
      "outputs": [],
      "source": [
        "#dishwashing\n",
        "to_replace = [\n",
        "    \"dishwash\", \"dishwashing liquid\",\"dishwashing\",\"dishwasing\",\"dishwash+hand soap\"\n",
        "]\n",
        "# Replace each instance in 'product_type' with 'shampoo'\n",
        "df['product_type'] = df['product_type'].replace(to_replace, 'dishwashing')\n",
        "\n",
        "\n",
        "#laundry\n",
        "to_replace = [\n",
        "    \"laundry\", \"laundry power\", \"laundry gel\"\n",
        "]\n",
        "df['product_type'] = df['product_type'].replace(to_replace, 'laundry gel')\n",
        "\n",
        "\n",
        "#fabric softner\n",
        "df['product_type'] = df['product_type'].replace('fabric siftner', 'fabric softner')\n",
        "\n",
        "\n",
        "#hand soap\n",
        "to_replace = [\n",
        "    \"hnd sop\", \"hnd sp\",\"hndsoap\",\"1l*2+hand soap\",\"handsoap\"\n",
        "]\n",
        "df['product_type'] = df['product_type'].replace(to_replace, 'hand soap')\n",
        "\n",
        "\n",
        "#shower gel\n",
        "df['product_type'] = df['product_type'].replace(\"showergel\", 'shower gel')\n",
        "\n",
        "\n",
        "#fabric softner\n",
        "df['product_type'] = df['product_type'].replace(\"fabric softener\", 'fabric softner')\n",
        "\n",
        "replacement_dict = {\n",
        "    \"bathroom cleaner\": [\"bathroom cleaner+sur\", \"bathroom cleaning\", \"antibacterial bathro\"],\n",
        "    \"toilet cleaner\": [\"toilet gel cleaner\"],\n",
        "    \"alcohol\": [\"alcohol spray\", \"pure alcohol\"],\n",
        "    \"oxidant\": [\"oxydant\"],\n",
        "    \"flash\": [\"flush\"],\n",
        "    \"disinfectant\": [\"disinfectant cleaner\", \"bowl disinfectant\"],\n",
        "    \"hair conditioner\": [\"conditioner\", \"bone marrow conditioning\", \"anti-oxidant conditioner\", \"conditioning mask\",\n",
        "                        \"shampoo &conditioner\", \"bone marrow conditioning mask\", \"straightening conditioner\",\n",
        "                        \"collagen conditioner\", \"salon conditioner\", \"anti-oxidant conditi\", \"cond\", \"cond mask\"],\n",
        "    \"hair remover\": [\"r.was\", \"wax\", \"hair remov\"],\n",
        "    \"thinning scissors\" : [\"thng.scrs\"],\n",
        "    \"developer cream\" : [\"dev.cream\"],\n",
        "    \"hair dye\": [\"vitality hair dye\"],\n",
        "    \"keratin\": [\"keratin serum\", \"keratine collagen\",\"k.keratine collagen\"],\n",
        "    \"glass cleaner\" : [\"hostpital\"],\n",
        "    \"lice remover\" : [\"cream\"]\n",
        "}\n",
        "\n",
        "df['product_type'] = df['product_type'].replace(\"cream\", 'lice remover')\n",
        "# Replace values in 'product_type'\n",
        "for new_value, old_values in replacement_dict.items():\n",
        "    df['product_type'].replace(old_values, new_value, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkvb8gOXXvU"
      },
      "source": [
        "####3.5-3) create Category and Subcategory Columns in df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gZeIharR-3qe"
      },
      "outputs": [],
      "source": [
        "df['product_type'] = df['product_type'].str.lower().str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1qFhvVuthDTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec1f239-4c5e-48cc-e06e-c21f30c01e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shampoo             45354\n",
            "dishwashing         19656\n",
            "laundry gel          7048\n",
            "general cleaner      4678\n",
            "hand soap            4421\n",
            "                    ...  \n",
            "housing comple          1\n",
            "fascinelle spray        1\n",
            "anti-oxidant            1\n",
            "lith clipper            1\n",
            "cooling spray           1\n",
            "Name: product_type, Length: 226, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check\n",
        "# Convert the 'product_type' column to lowercase\n",
        "df['product_type'] = df['product_type'].str.lower()\n",
        "\n",
        "# Count the occurrences of each unique value in the 'Brand' column\n",
        "type_counts = df['product_type'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "df_productDistnCounts = type_counts.to_csv(\"df_product_check.csv\")\n",
        "print(type_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GmzfmrIHE_1"
      },
      "source": [
        "we used df_productDistnCounts to create the dictionary by manually assigning distinct product types a category and subcategory. Its not the ideal approach but its the best course of action given the immense accuracy and work put into the cleaning process so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kbjFxFN91ChC"
      },
      "outputs": [],
      "source": [
        "df_PT_dict = pd.read_csv(\"/content/drive/MyDrive/Capstone/df_type_dict.csv\")\n",
        "\n",
        "# Convert all values in 'product_type' column to lowercase and strip leading/trailing spaces\n",
        "df_PT_dict['product_type'] = df_PT_dict['product_type'].str.lower().str.strip()\n",
        "df_PT_dict['product_type'] = df_PT_dict['product_type'].replace(\"keratine collagen\", \"keratin\")\n",
        "df_PT_dict['product_type'] = df_PT_dict['product_type'].replace(\"thng. scrs\", \"thinning scissors\")\n",
        "\n",
        "#Category\n",
        "df_PT_dict['Category '] = df_PT_dict['Category '].replace(\"Persnoal Care\", \"Personal Care\")\n",
        "\n",
        "###\n",
        "replacement_dict = {\n",
        "    \"Personal Care\" : [\"Persnoal Care\", \"Personal Care or Household Cleaning\", \"Beauty and Cosmetics or Health\", \"Personal Care or Art Supplies\"],\n",
        "    \"Others\": [\"Pet Supplies\", \"Hardware or Industrial\", \"Personal Care or Health\", \"Industrial or Household\", \"Stationery or Education\", \"Electronics or Construction\"]\n",
        "\n",
        "}\n",
        "\n",
        "# Replace values in 'product_type'\n",
        "for new_value, old_values in replacement_dict.items():\n",
        "    df_PT_dict['Category '].replace(old_values, new_value, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DbXFj71E05kH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdf29f3-03e2-400a-e6d8-0de31b246bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product types in df_PT_dict not present in df:\n",
            "thinning scissors\n"
          ]
        }
      ],
      "source": [
        "# Get unique product_type values from df_PT_dict\n",
        "unique_product_types_df_PT_dict = set(df_PT_dict['product_type'].unique())\n",
        "\n",
        "# Get unique product_type values from df\n",
        "unique_product_types_df = set(df['product_type'].unique())\n",
        "\n",
        "# Find product_type values in df_PT_dict not present in df\n",
        "product_types_not_in_df = unique_product_types_df_PT_dict - unique_product_types_df\n",
        "\n",
        "# Print the product types not present in df\n",
        "print(\"Product types in df_PT_dict not present in df:\")\n",
        "for product_type in product_types_not_in_df:\n",
        "    print(product_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LMiNRtgOSAlZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df and df_PT_dict are already loaded\n",
        "\n",
        "# Create mappings for Category and Subcategory from df_PT_dict\n",
        "category_mapping = df_PT_dict.set_index('product_type')['Category '].to_dict()\n",
        "subcategory_mapping = df_PT_dict.set_index('product_type')['Subcategory '].to_dict()\n",
        "\n",
        "# Map the values to df\n",
        "df['Category'] = df['product_type'].map(category_mapping)\n",
        "df['Subcategory'] = df['product_type'].map(subcategory_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9J212ZnsLZxr"
      },
      "outputs": [],
      "source": [
        "########## very important check point  ############\n",
        "df.to_csv(\"df_check.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BeSuFFYIC9w"
      },
      "source": [
        "make sure that no product_type value is not present in the dictionary to avoid any faults in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnio4r870rx2"
      },
      "source": [
        "###3.6) Extra Cleaning (Location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVqXpmg-E34-"
      },
      "source": [
        "do we add admin to intercompany"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fcQxG5nzAMAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407032ca-f904-4834-b1df-5438a7826afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method sum of numpy.ndarray object at 0x7ca8f5dade90>\n",
            "Unique Location IDs:\n",
            "['slska1' 'intercompany' 'slssth2' 'sprvsrsth' 'sprvsrbek' 'slsbek2'\n",
            " 'slsptc02m2' 'admin' 'slssbr' 'slsdbs' 'slsbrt' 'salons' 'slsmtn'\n",
            " 'pharmacies' 'export' 'slsmtn-ksn' 'sprvsrnor' 'slsksn-jbl' 'SLSSBR'\n",
            " 'SLSBRT' nan]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Get unique values from the 'Location ID' column\n",
        "unique_location_ids = df['Location ID'].unique()\n",
        "print(unique_location_ids.sum)\n",
        "# Print the unique values\n",
        "print(\"Unique Location IDs:\")\n",
        "print(unique_location_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w8pwJeTS-iAR"
      },
      "outputs": [],
      "source": [
        "location_dic = {\n",
        "    \"all branches\" : [\"Slska1\"],\n",
        "    \"South\" : [\"slssth2\"],\n",
        "    \"North\" : [\"sprvsrnor\"],\n",
        "    \"Baalbek-Hermel\": [\"slsbek2\"],\n",
        "    \"Beirut\" : [\"slsbrt\",\"SLSBRT\"],\n",
        "    \"Beqaa\" : [\"sprvsrbek\",],\n",
        "    \"Kesrwen-Jbeil\" : [\"slsmtn-ksn\",\"slsksn-jbl\",\"slsmtn\"],\n",
        "    \"Mount Lebanon\": [\"slssbr\", \"SLSSBR\"],\n",
        "    \"Nabatieh\" : [\"sprvsrsth\"],\n",
        "    \"intercompany\" : [\"slsptc02m2\"]\n",
        "}\n",
        "for new_value, old_values in location_dic.items():\n",
        "    df['Location ID'].replace(old_values, new_value, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OyaZ4J0HEb00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f33aa26-33f0-499d-9d3d-0d60021e8401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15 distinct items.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Count the number of distinct items\n",
        "distinct_Locations = df['Location ID'].nunique()\n",
        "\n",
        "# Print the count of distinct items\n",
        "print(f\"There are {distinct_Locations} distinct items.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooucBMfPGrIa"
      },
      "source": [
        "###3.7) Extra columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HHEtzjd2GC4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "0c68bf0f-f522-458c-a9d6-7f1540839339"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-97c7390ecaeb>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Apply the function to create the 'With Offer' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'With Offer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Item Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_offer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Count the number of items with and without offers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-97c7390ecaeb>\u001b[0m in \u001b[0;36mcheck_offer\u001b[0;34m(description)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function to check for a plus sign in the item description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_offer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'+'\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Apply the function to create the 'With Offer' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Function to check for a plus sign in the item description\n",
        "def check_offer(description):\n",
        "    return 1 if '+' | '*' in description else 0\n",
        "\n",
        "# Apply the function to create the 'With Offer' column\n",
        "df['With Offer'] = df['Item Description'].apply(check_offer)\n",
        "\n",
        "# Count the number of items with and without offers\n",
        "offer_counts = df['With Offer'].value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(\"Number of items with offers:\", offer_counts.get(1, 0))\n",
        "print(\"Number of items without offers:\", offer_counts.get(0, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8TV9BQVKmMt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Convert 'Document Date' to datetime if it's not already\n",
        "df['Document Date'] = pd.to_datetime(df['Document Date'])\n",
        "\n",
        "# Extract day, month, and year\n",
        "df['Day'] = df['Document Date'].dt.day\n",
        "df['Month'] = df['Document Date'].dt.month\n",
        "df['Year'] = df['Document Date'].dt.year\n",
        "\n",
        "# Now df will have new columns 'Day', 'Month', and 'Year'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q1lN8stKt_C"
      },
      "outputs": [],
      "source": [
        "print(df[['Document Date', 'Day', 'Month', 'Year']].iloc[4459]) #working well"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.8) Customer Names Cleaning"
      ],
      "metadata": {
        "id": "zOHAD5GqmWcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here we're going to remove ID's own retailers\n",
        "import pandas as pd\n",
        "\n",
        "# Define your multiple conditions\n",
        "customer_names = ['customers cash/wtc03', 'customers cash/', 'customers cash_']\n",
        "location_ids = ['intercompany', 'admin', 'slsdbs', 'slsptc02m2']\n",
        "\n",
        "\n",
        "# Filter df_frm based on these conditions\n",
        "condition = df_frm['Customer Name'].isin(customer_names) | df_frm['Location ID'].isin(location_ids)\n",
        "filtered_df = df_frm[condition]\n",
        "\n",
        "# Create list of unique customer numbers\n",
        "unique_customer_numbers = filtered_df['Customer Number'].unique()\n",
        "\n",
        "# Drop these customers from df_rfm\n",
        "df_rfm = df_rfm[~df_rfm['Customer Number'].isin(unique_customer_numbers)]\n"
      ],
      "metadata": {
        "id": "gxLXWD6rmbgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVmsnqlrFrvU"
      },
      "source": [
        "##RFM Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCi5oNeXFwEA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stvNfMqEIIiv"
      },
      "outputs": [],
      "source": [
        "# create a dataset solely for working on RFM analysis\n",
        "df_rfm = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGP8biQFFw0Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Group by 'Item Description' and sum the 'Extended Price'\n",
        "grouped_data = df_rfm.groupby('Item Description')['Extended Price'].sum().reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "grouped_data.columns = ['Item Description', 'Total Extended Price']\n",
        "\n",
        "#sort data\n",
        "sorted_data = grouped_data.sort_values(by='Total Extended Price', ascending=False)\n",
        "\n",
        "# Output the result\n",
        "print(sorted_data.head(40))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__Bmh_gOdwUd"
      },
      "outputs": [],
      "source": [
        "####### calculating the R F and M for our Customers  ###########\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Assuming your DataFrame is named df_rfm and it's already loaded\n",
        "# Also, assuming 'Document Date' is in a standard date format like 'YYYY-MM-DD'\n",
        "\n",
        "# Convert 'Document Date' to datetime\n",
        "df_rfm['Document Date'] = pd.to_datetime(df_rfm['Document Date'])\n",
        "\n",
        "# Determine your analysis date - typically one day after your latest date in the dataset\n",
        "latest_date = df_rfm['Document Date'].max() + pd.Timedelta(days = 1)\n",
        "\n",
        "# Calculate Recency (days since last purchase)\n",
        "recency = df_rfm.groupby('Customer Number')['Document Date'].max()\n",
        "recency = (latest_date - recency).dt.days\n",
        "recency = recency.reset_index()\n",
        "recency.columns = ['Customer Number', 'Recency']\n",
        "\n",
        "#Calculate Frequency (number of unique invoices per customer)\n",
        "frequency = df_rfm.groupby('Customer Number')['SOP Number'].nunique()\n",
        "frequency = frequency.reset_index()\n",
        "frequency.columns = ['Customer Number', 'Frequency']\n",
        "\n",
        "# Calculate Monetary (total money spent)\n",
        "monetary = df_rfm.groupby('Customer Number')['Extended Price'].sum()  # Replace 'Extended Price' with your monetary column name\n",
        "monetary = monetary.reset_index()\n",
        "monetary.columns = ['Customer Number', 'Monetary']\n",
        "\n",
        "# Merge the recency, frequency, and monetary dataframes\n",
        "df_rfm_segment = pd.merge(recency, frequency, on='Customer Number')\n",
        "df_rfm_segment = pd.merge(df_rfm_segment, monetary, on='Customer Number')\n",
        "\n",
        "# Display the first few rows of the RFM table\n",
        "print(df_rfm_segment.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp7pHJwCefxo"
      },
      "outputs": [],
      "source": [
        "df_rfm_segment.describe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total monetary value for each cluster\n",
        "total_monetary_per_cluster = df_rfm.groupby('Cluster')['Monetary'].sum()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=total_monetary_per_cluster.index, y=total_monetary_per_cluster.values)\n",
        "plt.title('Total Monetary Value per Segment')\n",
        "plt.xlabel('Segment (Cluster)')\n",
        "plt.ylabel('Total Monetary Value')\n",
        "plt.xticks(range(len(total_monetary_per_cluster)), ['Segment ' + str(i) for i in total_monetary_per_cluster.index])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vhtDRYMjF1MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftEZOisduyns"
      },
      "source": [
        "##checking for lstm cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8nXsYmX69e0"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFGUWuDD690S"
      },
      "outputs": [],
      "source": [
        "#fill na for product_scent\n",
        "df['product_scent'].fillna('neutral', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXMUYAFCG-x6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Replace this with your actual DataFrame loading or creation code\n",
        "\n",
        "# Filter the DataFrame for rows where 'Offer Status' is 'Yes'\n",
        "df_filtered = df[df['Offer Status'] == 'Offer']\n",
        "\n",
        "# Count the number of unique values in the 'Invoice' column\n",
        "unique_invoices_count = df_filtered['SOP Number'].nunique()\n",
        "\n",
        "print(f\"Number of unique invoices with 'Yes' in Offer Status: {unique_invoices_count}\")\n",
        "\n",
        "print((df[\"SOP Number\"]).nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nf1XGwvHeJc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ftEZOisduyns"
      ],
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "1vpzckM82PxWgyidiTpWYC5X4ezAgnG5Z",
      "authorship_tag": "ABX9TyP6Ilk76eXeFWLF7HES3z4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}